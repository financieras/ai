{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48ecf608-b0ca-4ea6-8356-2905d17d7b24",
   "metadata": {},
   "source": [
    "# Limpieza y Normalización de los DataFrames\n",
    "Vamos a limpiar y normalizar tanto los datos de entrenamiento 'train' como los de 'test'.\n",
    "\n",
    "| | original data | normalized data |\n",
    "|-------------------|---------------|-----------------|\n",
    "| training data | dataset_train.csv | normal_train.csv |\n",
    "| test data | dataset_test.csv | normal_test.csv \n",
    "\n",
    "Diferencias entre los datos de entrenamiento y de test originales:\n",
    "- Los datos de entrenamiento tienen 1600 registros y los de test tienen 400 registros.\n",
    "- Los datos de test tienen vacía la columna 'Hogwarts House' que es la columa objetivo de la clasificación.\n",
    "\n",
    "Trabajaremos con una versión reducida (lite5) que contiene:\n",
    "- Las características base:\n",
    "    1. 'Best Hand'\n",
    "    2. 'Age'\n",
    "- Las 5 asignaturas principales:\n",
    "    1. 'Defense Against the Dark Arts'\n",
    "    2. 'Herbology'\n",
    "    3. 'Potions'\n",
    "    4. 'Charms'\n",
    "    5. 'Flying'\n",
    "- Para los datos de entrenamiento también se incluyen las variables dummy de 'Hogwarts House'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4bdbb1-af72-403b-af05-8c7009d5a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Definición de las características que vamos a mantener\n",
    "BASE_FEATURES = ['Best Hand', 'Age']\n",
    "LITE5_COURSES = ['Defense Against the Dark Arts', 'Herbology',\n",
    "                 'Potions', 'Charms', 'Flying'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4724a530-c934-40b8-8b61-db270bb11635",
   "metadata": {},
   "source": [
    "## Lectura y preparación inicial de los datos\n",
    "\n",
    "Leemos los datasets originales y calculamos la edad a partir de la columna Birthday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a9aafa-9767-4c5b-9e6c-cc25c5a9d724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de los datasets\n",
    "file_train = '../datasets/dataset_train.csv'\n",
    "file_test = '../datasets/dataset_test.csv'\n",
    "\n",
    "df_train = pd.read_csv(file_train, index_col=0)\n",
    "df_test = pd.read_csv(file_test, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e03ee9-2b7e-409f-8d73-7742768b280f",
   "metadata": {},
   "source": [
    "## Imputación de datos faltantes usando 'Astronomy'\n",
    "Usamos la correlación perfecta r=-1 entre 'Astronomy' y 'Defense Against the Dark Arts' para realizar la imputación de los datos faltantes que se puedan imputar de 'Defense Against the Dark Arts' aprovechando esta característica.\n",
    "\n",
    "Lo único que hay que hacer es tomar el dato de 'Astronomy' y multiplicar por -0.01 para lograr conseguir el dato faltante de  'Defense Against the Dark Arts'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ed7b5-5e66-4f21-9f6f-6d04ce476171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputar 'Defense Against the Dark Arts' usando 'Astronomy'\n",
    "\n",
    "def data_imputation_perfect_correlation(df):\n",
    "    # Calcular las filas totales\n",
    "    total = len(df)\n",
    "    \n",
    "    # Calcular las filas con datos no nulos antes de la imputación\n",
    "    n1 = df['Defense Against the Dark Arts'].count()\n",
    "    \n",
    "    # Crear máscara para identificar:\n",
    "    # 1. Valores nulos en Defense Against the Dark Arts\n",
    "    # 2. Valores no nulos en Astronomy\n",
    "    mask = (df['Defense Against the Dark Arts'].isna() & \n",
    "            df['Astronomy'].notna())\n",
    "    \n",
    "    # Imputar los valores usando la relación perfecta (Astronomy * -0.01)\n",
    "    df.loc[mask, 'Defense Against the Dark Arts'] = df.loc[mask, 'Astronomy'] * -0.01\n",
    "    \n",
    "    # Calcular las filas con datos no nulos después de la imputación\n",
    "    n2 = df['Defense Against the Dark Arts'].count()\n",
    "    \n",
    "    # Verificar el resultado\n",
    "    print(\"Valores no nulos en Defense Against the Dark Arts:\")\n",
    "    print(f\"\\tAntes de imputación: {n1}/{total}\")\n",
    "    print(f\"\\tDespués de imputación: {n2}/{total}\")\n",
    "    \n",
    "    print(f\"\\nHemos recuperado {n2-n1} filas.\")\n",
    "\n",
    "# Aplicación a los dos DataFrame\n",
    "print(f\"{'='*13} Para el DataFrame train {'='*13}\")\n",
    "data_imputation_perfect_correlation(df_train)\n",
    "print()\n",
    "print(\"=\"*13, \"Para el DataFrame test\", \"=\"*13)\n",
    "data_imputation_perfect_correlation(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f510119-b476-434b-b447-49fa90a54e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5421ea9-b079-4d42-b748-7b8cef944f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c525d93-c547-41d7-a810-0638c64d3eb4",
   "metadata": {},
   "source": [
    "## Cálculo de la edad\n",
    "Es importante que la fecha que se tome como base (reference_date) para el cálculo de la edad en el DataFrame de entrenamiento se guarde en una variable para luego usarla como base en el cálculo de la edad en el DataFrame de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32090f63-1a97-459c-87f0-bf0d2d648aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, convertimos Birthday a datetime en ambos datasets\n",
    "df_train['Birthday'] = pd.to_datetime(df_train['Birthday'])\n",
    "df_test['Birthday'] = pd.to_datetime(df_test['Birthday'])\n",
    "\n",
    "# Calculamos la fecha de referencia usando solo el conjunto de entrenamiento\n",
    "reference_date = df_train['Birthday'].max()\n",
    "\n",
    "# Definimos la función para calcular la edad\n",
    "def calculate_age(df, reference_date):\n",
    "    df['Age'] = (reference_date - df['Birthday']).dt.days / 365.25\n",
    "    return df\n",
    "\n",
    "# Aplicamos el cálculo de edad a ambos datasets\n",
    "df_train = calculate_age(df_train, reference_date)\n",
    "df_test = calculate_age(df_test, reference_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fbed30-6113-45bb-8e6e-d7990083d54a",
   "metadata": {},
   "source": [
    "## Eliminación de columnas innecesarias\n",
    "Incluyendo 'Astronomy' después de usarla para la imputación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39200f57-ad96-4bc4-b0e7-037ecd77e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las columnas que no necesitamos\n",
    "columns_to_drop = ['First Name', 'Last Name', 'Birthday', 'Astronomy']\n",
    "df_train = df_train.drop(columns=columns_to_drop)\n",
    "df_test = df_test.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0b9649-7f17-4041-bf56-77a1787a7f12",
   "metadata": {},
   "source": [
    "## Conversión de datos categóricos a numéricos\n",
    "Convertimos 'Best Hand' a valores numéricos de tipo `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd4ab33-82bc-45f9-aeb0-d395774c5279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos Best Hand a valores numéricos en ambos datasets\n",
    "hand_mapping = {'Left': 0, 'Right': 1}\n",
    "df_train['Best Hand'] = df_train['Best Hand'].map(hand_mapping)\n",
    "df_test['Best Hand'] = df_test['Best Hand'].map(hand_mapping)\n",
    "\n",
    "# Convertimos Best Hand a float en ambos datasets\n",
    "df_train['Best Hand'] = df_train['Best Hand'].astype(float)\n",
    "df_test['Best Hand'] = df_test['Best Hand'].astype(float)\n",
    "\n",
    "# Verificamos la conversión\n",
    "print(\"Valores únicos en Best Hand (train):\", df_train['Best Hand'].unique())\n",
    "print(\"Valores únicos en Best Hand (test):\", df_test['Best Hand'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2218d158-7761-4814-960f-63bf1d3c8116",
   "metadata": {},
   "source": [
    "## Tratamiento específico para los datos de entrenamiento\n",
    "\n",
    "Para los datos de entrenamiento necesitamos hacer one-hot encoding de la columna 'Hogwarts House'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa9bc42-481f-4844-b7b3-bf5b8d67bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding solo para los datos de entrenamiento\n",
    "df_train = pd.get_dummies(df_train, columns=['Hogwarts House'], prefix='House', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee655a-6cc3-4e65-a165-45f222dfbef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualizamos BASE_FEATURES para incluir las columnas dummy de House\n",
    "HOUSE_FEATURES = ['House_Gryffindor', 'House_Hufflepuff', 'House_Ravenclaw', 'House_Slytherin']\n",
    "BASE_FEATURES = BASE_FEATURES + HOUSE_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7294ce-e660-4e68-b239-d250fc57ba4f",
   "metadata": {},
   "source": [
    "## Selección de características\n",
    "Seleccionamos solo las características de lite5 para luego normalizar las columnas numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1011b99e-1e64-4f2b-83d8-1d057bab9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las columnas que queremos mantener\n",
    "df_train = df_train[LITE5_COURSES + BASE_FEATURES]\n",
    "df_test = df_test[LITE5_COURSES + ['Best Hand', 'Age']]  # Note que no incluimos HOUSE_FEATURES para test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b58e481-35e8-43c7-b182-fea69ede0439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e605ed74-ade4-4ff8-b5a2-0a73204d0811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d1a942-5619-4159-81d2-5fcc4fd0be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(124)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ee0dc-880c-42fe-91da-d73a70fae1a2",
   "metadata": {},
   "source": [
    "### Eliminación de las filas con datos faltantes en 'train'\n",
    "- Se eliminan solo las filas de las características con las que se trabaja y solo del DataFrame 'df_train'.\n",
    "- En el 'df_test' no se elimina ninguna fila ya que luego aplicaremos un algoritmo de imputación para completar los datos faltantes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e14bfb8-0d1e-4989-b981-96df2dde16b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filas de los DataFrame previos a la eliminación de filas faltantes\n",
    "n_train = len(df_train)\n",
    "\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "print(f\"El DataFrame 'train' ha pasado de {n_train} a {len(df_train)} filas.\")\n",
    "print(f\"Se han eliminado {n_train - len(df_train)} registros con datos faltantes.\")\n",
    "print(f\"Se han eliminado solo el {n_train / len(df_train) - 1:.1%} de los registros, por este motivo no realizamos imputación de datos en 'train'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4130bc-61c5-41ac-bada-ef87534709cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aa4811-f447-4852-a4af-5fe1527ee4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(124)\n",
    "# Observe que el registro de Index 121 se ha eliminada ya que 'Herbology' tenía 'NaN' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec3e189-144a-41a3-a6c2-bf3294d3a2d7",
   "metadata": {},
   "source": [
    "# Normalización\n",
    "* Realizaremos la normalización antes de la imputación con el método de los k-vecinos más próximos (KNN) ya que:\n",
    "    - Es necesario normalizar las variables a una escala común antes de aplicar KNN.\n",
    "    - KNN se basa en el cálculo de distancias entre observaciones. Si hay variables con escalas muy diferentes, las variables con valores más grandes dominarán el cálculo de la distancia, sesgando los resultados\n",
    "* Es crucial usar EXACTAMENTE los mismos parámetros de normalización (media y desviación estándar) que se usen para los datos de entrenamiento cuando se aplique la normalización a los datos de test.\n",
    "* No se deben calcular nuevos parámetros con los datos de test.\n",
    "* Las variables dummy (también llamadas variables indicadoras o binarias) no deben normalizarse puesto que ya están en una escala fija (0 y 1),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee5b5fb-0a2f-4945-b645-6d66c0940351",
   "metadata": {},
   "source": [
    "### Función de Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98e1653-ed73-4247-9377-6b2dd66bf85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de normalización\n",
    "def normalize(column):\n",
    "    mean = column.mean()\n",
    "    std = column.std()\n",
    "    return (column - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac437e45-df6b-4bd6-9bbd-8e362bd48946",
   "metadata": {},
   "source": [
    "### Aplicación de la Normalización a ambos DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a483a68-5e7c-4c5c-9415-e5426061151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar las columnas a normalizar de las dummies\n",
    "# 'Best Hand' no se normalizará´\n",
    "features_to_normalize = ['Defense Against the Dark Arts', 'Herbology', 'Potions', \n",
    "                        'Charms', 'Flying', 'Age']\n",
    "\n",
    "# Normalizar df_train (excluyendo las variables dummy)\n",
    "for column in features_to_normalize:\n",
    "    mean = df_train[column].mean()\n",
    "    std = df_train[column].std()\n",
    "    \n",
    "    # Normalizar en train\n",
    "    df_train[column] = (df_train[column] - mean) / std\n",
    "    \n",
    "    # Usar los MISMOS parámetros para normalizar test\n",
    "    df_test[column] = (df_test[column] - mean) / std\n",
    "\n",
    "# Las variables dummy (HOUSE_FEATURES) se mantienen sin normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3dc758-e268-44e6-89e2-ffd49a261898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado del Datasets normalizado de entrenamiento\n",
    "df_train.to_csv('../datasets/normal_train.csv')\n",
    "# El Dataset de test aún no se graba puesto que faltan las imputaciones a datos faltantes\n",
    "\n",
    "print(\"Dimensiones del dataset de entrenamiento:\", df_train.shape)\n",
    "print(\"Dimensiones del dataset de test:\", df_test.shape)\n",
    "print(\"\\nColumnas en el dataset de entrenamiento:\\n\\t\", df_train.columns.tolist())\n",
    "print(\"\\nColumnas en el dataset de test:\\n\\t\", df_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6ab5bb-338d-479f-a2a8-1f691d7f4eb4",
   "metadata": {},
   "source": [
    "**Nota**\n",
    "- El Dataset de test contiene 400 registros pero aún contiene algunos registros con datos faltantes.\n",
    "- Aún tenemos que realizar la imputación con la técnica de los k-vecinos más próximos (KNN) [k-nearest neighbors algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b03ce1a-3b4f-4a26-bee0-177fe52108bd",
   "metadata": {},
   "source": [
    "# Imputación de datos faltantes en el Dataset 'test'\n",
    "Son pocos los registros que tienen algún dato faltante en el Dataset de `test`pero necesitamos que esten completos los 400 regitros para poder finalmente grabar el archivo 'houses.csv' que contendrá el resultado de nuestro entrenamiento aplicado a los datos de test. Es necesario que sean 400 registros por si se evalúan todos y cada uno de ellos confrontando nuestra estimación de la clasificación son los datos reales que nosotros no tenemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68769678-63cc-4160-82fe-cb48b9f2f7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar filas que tienen AL MENOS UN valor faltante\n",
    "n_rows_with_na = df_test.isna().any(axis=1).sum()\n",
    "print(f\"Filas con al menos un dato faltante en 'df_test': {n_rows_with_na}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017513f0-4b68-4765-a842-32e18ff63ae0",
   "metadata": {
    "id": "YQQuEOk0C1ph"
   },
   "source": [
    "## Imputación de datos faltantes con KNN usando solo filas completas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00592d37-c025-48d1-9a7f-7bc314886ebd",
   "metadata": {
    "id": "cA3p2jcbC1nd"
   },
   "source": [
    "### 1. Preparación de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7a7d81-7ba2-4696-8ad6-8cd884c80ff0",
   "metadata": {
    "id": "LML0XpO5C-q6"
   },
   "outputs": [],
   "source": [
    "# Identificar filas completas (sin valores faltantes)\n",
    "complete_rows = df_test.dropna()\n",
    "\n",
    "# Identificar filas con valores faltantes\n",
    "incomplete_rows = df_test[df_test.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478a24ec-b9a4-41b7-af95-cb83a72e10df",
   "metadata": {
    "id": "AEL70fNeDQTi"
   },
   "source": [
    "### 2. Función para calcular distancia euclidiana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26b0382-1499-445f-a0dd-91026a5c0c02",
   "metadata": {
    "id": "5w_XHjcHDTML"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(row1, row2, columns):\n",
    "    \"\"\"\n",
    "    Calcula la distancia euclidiana entre dos filas usando solo las columnas especificadas\n",
    "    \"\"\"\n",
    "    return np.sqrt(sum((row1[columns] - row2[columns])**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e6312d-a39e-4feb-a40a-aa883f8473a6",
   "metadata": {
    "id": "GdbK2cQ-DZbQ"
   },
   "source": [
    "### 3. Función para encontrar k vecinos más cercanos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a9bdb2-9444-4dd9-91a4-41161c3a29ed",
   "metadata": {
    "id": "almgrCHNDcgz"
   },
   "outputs": [],
   "source": [
    "def get_k_neighbors(target_row, complete_data, columns_to_use, k=5):\n",
    "    \"\"\"\n",
    "    Encuentra los k vecinos más cercanos para una fila dada\n",
    "    \"\"\"\n",
    "    distances = []\n",
    "    for idx, row in complete_data.iterrows():\n",
    "        dist = euclidean_distance(target_row, row, columns_to_use)\n",
    "        distances.append((idx, dist))\n",
    "\n",
    "    # Ordenar por distancia y obtener los k más cercanos\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    return [idx for idx, _ in distances[:k]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546ca9c9-e582-40a3-9b85-591567d13a35",
   "metadata": {
    "id": "4RzNdrdYDiSH"
   },
   "source": [
    "### 4. Función de imputación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece9c481-6794-4e4e-9020-817e807e9188",
   "metadata": {
    "id": "6nLSSSi7DnMg"
   },
   "outputs": [],
   "source": [
    "def impute_missing_values(df, k=5):\n",
    "    \"\"\"\n",
    "    Imputa valores faltantes usando KNN\n",
    "    \"\"\"\n",
    "    df_imputed = df.copy()\n",
    "    complete_data = df.dropna()\n",
    "\n",
    "    # Para cada fila con valores faltantes\n",
    "    for idx, row in df[df.isnull().any(axis=1)].iterrows():\n",
    "        # Identificar columnas con valores faltantes en esta fila\n",
    "        missing_cols = row[row.isnull()].index\n",
    "\n",
    "        # Identificar columnas disponibles para calcular distancias\n",
    "        available_cols = row[row.notnull()].index\n",
    "\n",
    "        # Encontrar k vecinos más cercanos\n",
    "        neighbors_idx = get_k_neighbors(row, complete_data, available_cols, k)\n",
    "\n",
    "        # Imputar cada columna faltante con la media de los vecinos\n",
    "        for col in missing_cols:\n",
    "            neighbor_values = complete_data.loc[neighbors_idx, col]\n",
    "            df_imputed.loc[idx, col] = neighbor_values.mean()\n",
    "\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646573f9-ec2d-4144-96ee-aadc8f86893c",
   "metadata": {
    "id": "T-V4KcpsDscf"
   },
   "source": [
    "### 5. Aplicación del proceso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef06311-5453-4c54-ae40-55c04cd53ea4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8ss-UXXDwS1",
    "outputId": "de0c31cc-9620-4527-8506-f7f5643efd49"
   },
   "outputs": [],
   "source": [
    "# Aplicar la imputación\n",
    "df_test_imputed = impute_missing_values(df_test, k=5)\n",
    "\n",
    "# Verificar resultados\n",
    "print(\"\\nVerificación de valores faltantes después de imputación:\")\n",
    "print(df_test_imputed.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3e5bd9-f067-4a00-bc99-9486a791b12a",
   "metadata": {},
   "source": [
    "### Grabación del Dataset de 'test' normalizado y sin datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cfe8d5-8192-457a-8b9c-64d9e938cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_imputed.to_csv('../datasets/normal_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
