{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48ecf608-b0ca-4ea6-8356-2905d17d7b24",
   "metadata": {},
   "source": [
    "# Normalize DataFrames\n",
    "Vamos a normalizar tanto los datos de entrenamiento 'train' como los de 'test'.\n",
    "\n",
    "| | original data | normalized data |\n",
    "|-------------------|---------------|-----------------|\n",
    "| training data | dataset_train.csv | normal_train.csv |\n",
    "| test data | dataset_test.csv | normal_test.csv \n",
    "\n",
    "Diferencias entre los datos de entrenamiento y de test originales:\n",
    "- Los datos de entrenamiento tienen 1600 registros y los de test 400 registros\n",
    "- Los datos de test tienen vacía la columna 'Hogwarts House' que es la columa objetivo de la clasificación.\n",
    "\n",
    "Trabajaremos con una versión reducida (lite5) que contiene:\n",
    "- Las características base:\n",
    "    1. 'Best Hand'\n",
    "    2. 'Age'\n",
    "- Las 5 asignaturas principales:\n",
    "    1. 'Defense Against the Dark Arts'\n",
    "    2. 'Herbology'\n",
    "    3. 'Potions'\n",
    "    4. 'Charms'\n",
    "    5. 'Flying'\n",
    "- Para los datos de entrenamiento también se incluyen las variables dummy de 'Hogwarts House'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb4bdbb1-af72-403b-af05-8c7009d5a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Definición de las características que vamos a mantener\n",
    "BASE_FEATURES = ['Best Hand', 'Age']\n",
    "LITE5_COURSES = ['Defense Against the Dark Arts', 'Herbology',\n",
    "                 'Potions', 'Charms', 'Flying'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4724a530-c934-40b8-8b61-db270bb11635",
   "metadata": {},
   "source": [
    "## Lectura y preparación inicial de los datos\n",
    "\n",
    "Leemos los datasets originales y calculamos la edad a partir de la columna Birthday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cbaec35-8a2a-45f3-9b8c-09e1c86341c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de los datasets\n",
    "file_train = '../datasets/dataset_train.csv'\n",
    "file_test = '../datasets/dataset_test.csv'\n",
    "\n",
    "df_train = pd.read_csv(file_train, index_col=0)\n",
    "df_test = pd.read_csv(file_test, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e03ee9-2b7e-409f-8d73-7742768b280f",
   "metadata": {},
   "source": [
    "## Imputación de datos faltantes usando 'Astronomy'\n",
    "Usamos la correlación perfecta r=-1 entre 'Astronomy' y 'Defense Against the Dark Arts' para realizar la imputación de los datos faltantes que se puedan imputar de 'Defense Against the Dark Arts' aprovechando esta característica.\n",
    "\n",
    "Lo único que hay que hacer es tomar el dato de 'Astronomy' y multiplicar por -0.01 para lograr conseguir el dato faltante de  'Defense Against the Dark Arts'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff1ed7b5-5e66-4f21-9f6f-6d04ce476171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Para el DataFrame train =============\n",
      "Valores no nulos en Defense Against the Dark Arts:\n",
      "Antes de imputación: 1569/1600\n",
      "Después de imputación: 1600/1600\n",
      "\n",
      "Hemos recuperado 31 filas.\n",
      "\n",
      "============= Para el DataFrame test =============\n",
      "Valores no nulos en Defense Against the Dark Arts:\n",
      "Antes de imputación: 392/400\n",
      "Después de imputación: 399/400\n",
      "\n",
      "Hemos recuperado 7 filas.\n"
     ]
    }
   ],
   "source": [
    "# Imputar 'Defense Against the Dark Arts' usando 'Astronomy'\n",
    "\n",
    "def data_imputation_perfect_correlation(df):\n",
    "    # Calcular las filas totales\n",
    "    total = len(df)\n",
    "    \n",
    "    # Calcular las filas con datos no nulos antes de la imputación\n",
    "    n1 = df['Defense Against the Dark Arts'].count()\n",
    "    \n",
    "    # Crear máscara para identificar:\n",
    "    # 1. Valores nulos en Defense Against the Dark Arts\n",
    "    # 2. Valores no nulos en Astronomy\n",
    "    mask = (df['Defense Against the Dark Arts'].isna() & \n",
    "            df['Astronomy'].notna())\n",
    "    \n",
    "    # Imputar los valores usando la relación perfecta (Astronomy * -0.01)\n",
    "    df.loc[mask, 'Defense Against the Dark Arts'] = df.loc[mask, 'Astronomy'] * -0.01\n",
    "    \n",
    "    # Calcular las filas con datos no nulos después de la imputación\n",
    "    n2 = df['Defense Against the Dark Arts'].count()\n",
    "    \n",
    "    # Verificar el resultado\n",
    "    print(\"Valores no nulos en Defense Against the Dark Arts:\")\n",
    "    print(f\"Antes de imputación: {n1}/{total}\")\n",
    "    print(f\"Después de imputación: {n2}/{total}\")\n",
    "    \n",
    "    print(f\"\\nHemos recuperado {n2-n1} filas.\")\n",
    "\n",
    "# Aplicación a los dos DataFrame\n",
    "print(f\"{'='*13} Para el DataFrame train {'='*13}\")\n",
    "data_imputation_perfect_correlation(df_train)\n",
    "print()\n",
    "print(\"=\"*13, \"Para el DataFrame test\", \"=\"*13)\n",
    "data_imputation_perfect_correlation(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f510119-b476-434b-b447-49fa90a54e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1600 entries, 0 to 1599\n",
      "Data columns (total 18 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Hogwarts House                 1600 non-null   object \n",
      " 1   First Name                     1600 non-null   object \n",
      " 2   Last Name                      1600 non-null   object \n",
      " 3   Birthday                       1600 non-null   object \n",
      " 4   Best Hand                      1600 non-null   object \n",
      " 5   Arithmancy                     1566 non-null   float64\n",
      " 6   Astronomy                      1568 non-null   float64\n",
      " 7   Herbology                      1567 non-null   float64\n",
      " 8   Defense Against the Dark Arts  1600 non-null   float64\n",
      " 9   Divination                     1561 non-null   float64\n",
      " 10  Muggle Studies                 1565 non-null   float64\n",
      " 11  Ancient Runes                  1565 non-null   float64\n",
      " 12  History of Magic               1557 non-null   float64\n",
      " 13  Transfiguration                1566 non-null   float64\n",
      " 14  Potions                        1570 non-null   float64\n",
      " 15  Care of Magical Creatures      1560 non-null   float64\n",
      " 16  Charms                         1600 non-null   float64\n",
      " 17  Flying                         1600 non-null   float64\n",
      "dtypes: float64(13), object(5)\n",
      "memory usage: 237.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5421ea9-b079-4d42-b748-7b8cef944f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 400 entries, 0 to 399\n",
      "Data columns (total 18 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Hogwarts House                 0 non-null      float64\n",
      " 1   First Name                     400 non-null    object \n",
      " 2   Last Name                      400 non-null    object \n",
      " 3   Birthday                       400 non-null    object \n",
      " 4   Best Hand                      400 non-null    object \n",
      " 5   Arithmancy                     387 non-null    float64\n",
      " 6   Astronomy                      387 non-null    float64\n",
      " 7   Herbology                      389 non-null    float64\n",
      " 8   Defense Against the Dark Arts  399 non-null    float64\n",
      " 9   Divination                     394 non-null    float64\n",
      " 10  Muggle Studies                 390 non-null    float64\n",
      " 11  Ancient Runes                  392 non-null    float64\n",
      " 12  History of Magic               389 non-null    float64\n",
      " 13  Transfiguration                389 non-null    float64\n",
      " 14  Potions                        390 non-null    float64\n",
      " 15  Care of Magical Creatures      392 non-null    float64\n",
      " 16  Charms                         400 non-null    float64\n",
      " 17  Flying                         400 non-null    float64\n",
      "dtypes: float64(14), object(4)\n",
      "memory usage: 59.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c936f2b6-664e-43e9-be4c-c64c5085240d",
   "metadata": {},
   "source": [
    "## Eliminación de 'Astronomy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "117d1a79-a830-4b3f-98cd-2f896dc86763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna 'Astronomy' después de usarla para la imputación\n",
    "df_train = df_train.drop('Astronomy', axis=1)\n",
    "df_test = df_test.drop('Astronomy', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c525d93-c547-41d7-a810-0638c64d3eb4",
   "metadata": {},
   "source": [
    "### Cálculo de la edad\n",
    "Es importante que la fecha que se tome como base (reference_date) para el cálculo de la edad en el DataFrame de entrenamiento se guarde en una variable para luego usarla como base en el cálculo de la edad en el DataFrame de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32090f63-1a97-459c-87f0-bf0d2d648aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, convertimos Birthday a datetime en ambos datasets\n",
    "df_train['Birthday'] = pd.to_datetime(df_train['Birthday'])\n",
    "df_test['Birthday'] = pd.to_datetime(df_test['Birthday'])\n",
    "\n",
    "# Calculamos la fecha de referencia usando solo el conjunto de entrenamiento\n",
    "reference_date = df_train['Birthday'].max()\n",
    "\n",
    "# Definimos la función para calcular la edad\n",
    "def calculate_age(df, reference_date):\n",
    "    df['Age'] = (reference_date - df['Birthday']).dt.days / 365.25\n",
    "    return df\n",
    "\n",
    "# Aplicamos el cálculo de edad a ambos datasets\n",
    "df_train = calculate_age(df_train, reference_date)\n",
    "df_test = calculate_age(df_test, reference_date)\n",
    "\n",
    "\n",
    "# Eliminamos las columnas que no necesitamos\n",
    "columns_to_drop = ['First Name', 'Last Name', 'Birthday']\n",
    "df_train = df_train.drop(columns=columns_to_drop)\n",
    "df_test = df_test.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0b9649-7f17-4041-bf56-77a1787a7f12",
   "metadata": {},
   "source": [
    "### Convertimos 'Best Hand' a valores numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd4ab33-82bc-45f9-aeb0-d395774c5279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en Best Hand (train): [0. 1.]\n",
      "Valores únicos en Best Hand (test): [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Convertimos Best Hand a valores numéricos en ambos datasets\n",
    "hand_mapping = {'Left': 0, 'Right': 1}\n",
    "df_train['Best Hand'] = df_train['Best Hand'].map(hand_mapping)\n",
    "df_test['Best Hand'] = df_test['Best Hand'].map(hand_mapping)\n",
    "\n",
    "# Convertimos Best Hand a float en ambos datasets\n",
    "df_train['Best Hand'] = df_train['Best Hand'].astype(float)\n",
    "df_test['Best Hand'] = df_test['Best Hand'].astype(float)\n",
    "\n",
    "# Verificamos la conversión\n",
    "print(\"Valores únicos en Best Hand (train):\", df_train['Best Hand'].unique())\n",
    "print(\"Valores únicos en Best Hand (test):\", df_test['Best Hand'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2218d158-7761-4814-960f-63bf1d3c8116",
   "metadata": {},
   "source": [
    "## Tratamiento específico para los datos de entrenamiento\n",
    "\n",
    "Para los datos de entrenamiento necesitamos hacer one-hot encoding de la columna 'Hogwarts House'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fa9bc42-481f-4844-b7b3-bf5b8d67bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding solo para los datos de entrenamiento\n",
    "df_train = pd.get_dummies(df_train, columns=['Hogwarts House'], prefix='House', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10ee655a-6cc3-4e65-a165-45f222dfbef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualizamos BASE_FEATURES para incluir las columnas dummy de House\n",
    "HOUSE_FEATURES = ['House_Gryffindor', 'House_Hufflepuff', 'House_Ravenclaw', 'House_Slytherin']\n",
    "BASE_FEATURES = BASE_FEATURES + HOUSE_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7294ce-e660-4e68-b239-d250fc57ba4f",
   "metadata": {},
   "source": [
    "## Selección de características\n",
    "Seleccionamos solo las características de lite5 para luego normalizar las columnas numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1011b99e-1e64-4f2b-83d8-1d057bab9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las columnas que queremos mantener\n",
    "df_train = df_train[LITE5_COURSES + BASE_FEATURES]\n",
    "df_test = df_test[LITE5_COURSES + ['Best Hand', 'Age']]  # Note que no incluimos HOUSE_FEATURES para test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b58e481-35e8-43c7-b182-fea69ede0439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1600 entries, 0 to 1599\n",
      "Data columns (total 11 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Defense Against the Dark Arts  1600 non-null   float64\n",
      " 1   Herbology                      1567 non-null   float64\n",
      " 2   Potions                        1570 non-null   float64\n",
      " 3   Charms                         1600 non-null   float64\n",
      " 4   Flying                         1600 non-null   float64\n",
      " 5   Best Hand                      1600 non-null   float64\n",
      " 6   Age                            1600 non-null   float64\n",
      " 7   House_Gryffindor               1600 non-null   float64\n",
      " 8   House_Hufflepuff               1600 non-null   float64\n",
      " 9   House_Ravenclaw                1600 non-null   float64\n",
      " 10  House_Slytherin                1600 non-null   float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e605ed74-ade4-4ff8-b5a2-0a73204d0811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 400 entries, 0 to 399\n",
      "Data columns (total 7 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Defense Against the Dark Arts  399 non-null    float64\n",
      " 1   Herbology                      389 non-null    float64\n",
      " 2   Potions                        390 non-null    float64\n",
      " 3   Charms                         400 non-null    float64\n",
      " 4   Flying                         400 non-null    float64\n",
      " 5   Best Hand                      400 non-null    float64\n",
      " 6   Age                            400 non-null    float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 25.0 KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ee0dc-880c-42fe-91da-d73a70fae1a2",
   "metadata": {},
   "source": [
    "### Eliminación de las filas con datos faltantes en 'train'\n",
    "- Se eliminan solo las filas de las características con las que se trabaja y solo del DataFrame 'df_train'.\n",
    "- En el 'df_test' no se elimina ninguna fila ya que luego aplicaremos un algoritmo de imputación para completar los datos faltantes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e14bfb8-0d1e-4989-b981-96df2dde16b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame 'train' ha pasado de 1600 a 1537 filas.\n",
      "Se han eliminado 63 registros con datos faltantes.\n",
      "Se han eliminado solo el 4.1% de los registros, por este motivo no realizamos imputación de datos en 'train'.\n"
     ]
    }
   ],
   "source": [
    "# Filas de los DataFrame previos a la eliminación de filas faltantes\n",
    "n_train = len(df_train)\n",
    "\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "print(f\"El DataFrame 'train' ha pasado de {n_train} a {len(df_train)} filas.\")\n",
    "print(f\"Se han eliminado {n_train - len(df_train)} registros con datos faltantes.\")\n",
    "print(f\"Se han eliminado solo el {n_train / len(df_train) - 1:.1%} de los registros, por este motivo no realizamos imputación de datos en 'train'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec3e189-144a-41a3-a6c2-bf3294d3a2d7",
   "metadata": {},
   "source": [
    "## Normalización\n",
    "* Realizaremos la normalización antes de la imputación con el método de los k-vecinos más próximos (KNN) ya que:\n",
    "    - Es necesario normalizar las variables a una escala común antes de aplicar KNN.\n",
    "    - KNN se basa en el cálculo de distancias entre observaciones. Si hay variables con escalas muy diferentes, las variables con valores más grandes dominarán el cálculo de la distancia, sesgando los resultados\n",
    "* Es crucial usar EXACTAMENTE los mismos parámetros de normalización (media y desviación estándar) que se usen para los datos de entrenamiento cuando se aplique la normalización a los datos de test.\n",
    "* No se deben calcular nuevos parámetros con los datos de test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee5b5fb-0a2f-4945-b645-6d66c0940351",
   "metadata": {},
   "source": [
    "### Función de Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d98e1653-ed73-4247-9377-6b2dd66bf85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de normalización\n",
    "def normalize(column):\n",
    "    mean = column.mean()\n",
    "    std = column.std()\n",
    "    return (column - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac437e45-df6b-4bd6-9bbd-8e362bd48946",
   "metadata": {},
   "source": [
    "### Aplicación de la Normalización a ambos DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e3cb2a-f135-4aad-a2e5-267eba65f1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0682c86-6ea1-48aa-9f6e-c7fabd02fc23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524fa6e8-138b-49fa-a716-d81d9b59c33a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7764137c-2eda-4937-860b-bb7742c3e61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas normalizadas en train:\n",
      " ['Herbology', 'Defense Against the Dark Arts', 'Potions', 'Charms', 'Flying', 'Best Hand', 'Age', 'House_Gryffindor', 'House_Hufflepuff', 'House_Ravenclaw', 'House_Slytherin']\n",
      "\n",
      "Columnas normalizadas en test:\n",
      " ['Herbology', 'Defense Against the Dark Arts', 'Potions', 'Charms', 'Flying', 'Best Hand', 'Age']\n"
     ]
    }
   ],
   "source": [
    "# Para el dataset de entrenamiento\n",
    "train_columns_to_normalize = df_train.select_dtypes(include=['float64']).columns.tolist()\n",
    "df_train[train_columns_to_normalize] = df_train[train_columns_to_normalize].apply(normalize)\n",
    "\n",
    "# Para el dataset de test (que no incluye las columnas de House)\n",
    "test_columns_to_normalize = df_test.select_dtypes(include=['float64']).columns.tolist()\n",
    "df_test[test_columns_to_normalize] = df_test[test_columns_to_normalize].apply(normalize)\n",
    "\n",
    "# Verificamos las columnas normalizadas\n",
    "print(\"Columnas normalizadas en train:\\n\", train_columns_to_normalize)\n",
    "print(\"\\nColumnas normalizadas en test:\\n\", test_columns_to_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b3dc758-e268-44e6-89e2-ffd49a261898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del dataset de entrenamiento: (1600, 11)\n",
      "Dimensiones del dataset de test: (400, 7)\n",
      "\n",
      "Columnas en el dataset de entrenamiento: ['Herbology', 'Defense Against the Dark Arts', 'Potions', 'Charms', 'Flying', 'Best Hand', 'Age', 'House_Gryffindor', 'House_Hufflepuff', 'House_Ravenclaw', 'House_Slytherin']\n",
      "\n",
      "Columnas en el dataset de test: ['Herbology', 'Defense Against the Dark Arts', 'Potions', 'Charms', 'Flying', 'Best Hand', 'Age']\n"
     ]
    }
   ],
   "source": [
    "# Guardado de los datasets normalizados\n",
    "df_train.to_csv('../datasets/normal_train.csv')\n",
    "df_test.to_csv('../datasets/normal_test.csv')\n",
    "\n",
    "print(\"Dimensiones del dataset de entrenamiento:\", df_train.shape)\n",
    "print(\"Dimensiones del dataset de test:\", df_test.shape)\n",
    "print(\"\\nColumnas en el dataset de entrenamiento:\", df_train.columns.tolist())\n",
    "print(\"\\nColumnas en el dataset de test:\", df_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d28a21-a782-45a9-8ec4-712a405b10f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
