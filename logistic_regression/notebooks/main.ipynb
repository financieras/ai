{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzRXAT4X2h46"
   },
   "source": [
    "# Logistic Regression\n",
    "Proyecto de regresión logística multinomial para clasificar estudiantes en las casas de Hogwarts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cs_wUWRWzVHC"
   },
   "source": [
    "## Estructura del proyecto\n",
    "\n",
    "### datasets/\n",
    "- dataset_train.csv\n",
    "- dataset_test.csv\n",
    "\n",
    "### notebooks/\n",
    "0. main.ipynb\n",
    "1. exploratory.ipynb\n",
    "2. describe.ipynb\n",
    "3. histogram.ipynb\n",
    "4. scatter_plot.ipynb\n",
    "5. pair_plot.ipynb\n",
    "6. normalize.ipynb\n",
    "7. logreg_train.ipynb\n",
    "8. logreg_predict.ipynb\n",
    "\n",
    "### src/\n",
    "- ft_functions.py\n",
    "\n",
    "### output/\n",
    "- correlation_heatmap.png\n",
    "- houses.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido de los Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. exploratory.ipynb\n",
    "1. Introducción: Explica que el proyecto es de Regresión Logística para clasificación multinomial.\n",
    "2. Datos de entrada: Se mencionan dos conjuntos de datos (dataset_train.csv y dataset_test.csv).\n",
    "3. Carga de datos: Se usa pandas para leer los archivos y convertirlos en DataFrame.\n",
    "4. Estructura de los datos: Se analizan los datasets con df_train.info() y df_test.info().\n",
    "5. Exploración inicial: Se revisan valores nulos y categorías únicas en variables nominales.\n",
    "6. Análisis de correlaciones: Se genera un mapa de calor en 'output/correlation_heatmap.png'\n",
    "7. Detecta correlaciones perfectas: Sugiere eliminar 'Astronomy'\n",
    "8. Columna a eliminar: La columna a eliminar se guarda en 'output/column_to_drop.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. describe.ipynb\n",
    "1. Introducción: Explica que el Notebook realiza análisis estadístico descriptivo sobre los datos de entrenamiento.\n",
    "2. Verificación del directorio: Se usa `os` para mostrar la ubicación actual del script.\n",
    "3. Configuración del entorno: Se modifica el `sys.path` para importar funciones desde `src.ft_functions`.\n",
    "4. Cálculo de métricas: Se define `calculate_metrics(df)` para obtener estadísticas de columnas numéricas.\n",
    "5. Impresión de métricas: Se implementa `print_metrics_table(metrics)` para mostrar resultados en una tabla.\n",
    "6. Análisis del dataset: `analyze_dataset()` carga los datos y ejecuta los cálculos estadísticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. histogram.ipynb\n",
    "1. Introducción: Genera y guarda un histograma comparando las distribuciones de puntuaciones entre las casas de Hogwarts para cada curso.\n",
    "2. Carga de datos: Se lee el archivo `dataset_train.csv` y se convierte en un DataFrame de Pandas.\n",
    "3. Selección de cursos: Se identifican las columnas correspondientes a los cursos dentro del DataFrame y se excluye 'Astronomy'\n",
    "4. Creación de gráficos: Se genera una figura con subgráficos para cada curso, mostrando la distribución de puntuaciones por casa.\n",
    "5. Grabación del png: Se graba el histograma en 'output/histogram.png'\n",
    "6. Análisis de homogeneidad: Se responde a la pregunta sobre qué curso tiene una distribución homogénea entre todas las casas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. scatter_plot.ipynb\n",
    "1. Propósito: Identificar las dos materias con mayor correlación en el conjunto de datos y visualizarlas mediante un diagrama de dispersión.\n",
    "2. Procesamiento: Lee `dataset_train.csv`, elimina 'Astronomy' y calcula la matriz de correlación entre materias.\n",
    "3. Análisis: Encuentra automáticamente las materias más correlacionadas ('History of Magic' y 'Flying') con un coeficiente de -0.896.\n",
    "4. Limpieza: Elimina los registros con valores nulos en ambas características.\n",
    "5. Visualización: Crea un gráfico de dispersión (scatter plot) de las dos materias con la correlación más alta. Incluye la línea de tendencia y el coeficiente de correlación.\n",
    "6. Resultado: Guarda el gráfico en `output/scatter_plot.png`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. pair_plot.ipynb\n",
    "1. Objetivo: Crear un pair plot para identificar las características más útiles para la regresión logística.\n",
    "2. Carga de datos: Lee `dataset_train.csv` y extrae las columnas de cursos, excluyendo 'Astronomy'.\n",
    "3. Limpieza: Elimina filas con datos faltantes en el DataFrame.\n",
    "4. Visualización: Crea un 'pair plot' utilizando `seaborn`, que muestra la distribución de cada variable y las relaciones entre pares de variables.\n",
    "5. Gráfico: Guardado en `output/pair_plot.png`.\n",
    "6. Análisis de las visualizaciones: Cursos que muestran mejor separación entre las casas y por lo tanto son más útiles para la regresión logística:\n",
    "    1. Defense Against the Dark Arts'\n",
    "    2. 'Herbology'\n",
    "    3. 'Potions'\n",
    "    4. 'Charms'\n",
    "    5. 'Flying' \n",
    "8. Identificación: Identifica los cursos que muestran mayor superposición y serían menos útiles para el modelo:  y cuáles serían más útiles para el modelo de regresión logística.\n",
    "    - 'History of Magic'\n",
    "    - 'Muggle Studies'\n",
    "    - 'Ancient Runes'\n",
    "    - 'Arithmancy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. normalize.ipynb\n",
    "1. Limpieza y normalización de los dos DataFrames.\n",
    "2. Imputación de datos faltantes en 'Defense Against the Dark Arts' usando la correlación perfecta con 'Astronomy', en train y test.\n",
    "3. Eliminación de columnas innecesarias, incluyendo 'Astronomy'\n",
    "4. Cálculo de la edad a partir de fechas\n",
    "5. Conversión de datos categóricos a numéricos ('Best Hand' a `float`)\n",
    "6. Normalización de variables numéricas.\n",
    "    - Normalización con media ('mean') y desviación estandar ('standard deviation') de los datos de entrenamiento\n",
    "    - Se procesa el conjunto de test de manera idéntica al de entrenamiento, usando los mismos parámetros de normalización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. logreg_train.ipynb\n",
    "Se implementa un modelo de regresión logística multinomial con:\n",
    "   - Función softmax para probabilidades multiclase\n",
    "   - Función de pérdida cross-entropy\n",
    "   - Descenso del gradiente para optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. logreg_predict.ipynb\n",
    "- Se genera un archivo de predicciones con la casa asignada a cada estudiante con los datos de test.\n",
    "- Salida `houses.csv`: archivo con dos columnas (Index, Hogwarts House) que contiene las predicciones de casa para cada estudiante del conjunto de test"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNfv+4e9JE0HDXccPtrCcbu",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
