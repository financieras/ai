{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIfbcQGDDeZ6jkdWdy8n4R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/financieras/ai/blob/main/logistic_regression/src/sigmoide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n",
        "\n",
        "Pasos básicos para implementar la regresión logística \"desde cero\" usando el descenso del gradiente:\n",
        "\n",
        "1. Preparación de los datos:\n",
        "\n",
        "Separar la variable objetivo (House_Gryffindor) de las características\n",
        "Agregar una columna de 1's para el término de sesgo (bias)\n",
        "Separar los datos en conjuntos de entrenamiento y prueba\n",
        "\n",
        "\n",
        "2. Función Sigmoide:\n",
        "\n",
        "Necesitaremos implementar la función sigmoide: σ(z) = 1/(1 + e^(-z))\n",
        "Esta función transformará nuestras predicciones lineales en probabilidades entre 0 y 1\n",
        "\n",
        "\n",
        "3. Función de Pérdida:\n",
        "\n",
        "Implementar la función de pérdida logarítmica (log loss)\n",
        "Esta función mide qué tan bien están funcionando nuestras predicciones\n",
        "Para regresión logística se usa la pérdida logarítmica binaria\n",
        "\n",
        "\n",
        "4. Gradiente:\n",
        "\n",
        "Calcular el gradiente de la función de pérdida con respecto a los pesos\n",
        "Para regresión logística, el gradiente es: X^T * (h(X) - y) / m\n",
        "Donde X son las características, h(X) son las predicciones, y son los valores reales, m es el número de muestras\n",
        "\n",
        "\n",
        "5. Descenso del Gradiente:\n",
        "\n",
        "Inicializar los pesos (pueden ser todos ceros o aleatorios)\n",
        "Por cada iteración:\n",
        "\n",
        "Calcular las predicciones usando la función sigmoide\n",
        "Calcular el gradiente\n",
        "Actualizar los pesos: w = w - α * gradiente\n",
        "α es la tasa de aprendizaje (learning rate)\n",
        "\n",
        "6. Criterio de Parada:\n",
        "\n",
        "Definir un número máximo de iteraciones\n",
        "O establecer un umbral mínimo de cambio en la función de pérdida\n",
        "O ambos\n",
        "\n",
        "7. Evaluación en datos de entrenamiento:\n",
        "\n",
        "Hacer predicciones con los pesos optimizados\n",
        "Convertir probabilidades a clases (0 o 1)\n",
        "Calcular Accuracy en datos de entrenamiento\n",
        "\n",
        "\n",
        "8. Evaluación en datos de test:\n",
        "\n",
        "Cargar y preparar datos de test (añadir columna de 1's)\n",
        "Hacer predicciones con los pesos optimizados\n",
        "Calcular Accuracy en datos de test\n",
        "Comparar Accuracy de train vs test para detectar posible sobreajuste"
      ],
      "metadata": {
        "id": "tB9qonV4KpWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Partimos del archivo 'dataset_normalized_lite5.csv' que ya está normalizado y preparado.\n",
        "\n",
        "El archivo está en Google Drive por lo que lo leemos y construimos un DataFrame."
      ],
      "metadata": {
        "id": "wWB1xXe5kGUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYwTVx86JHDe",
        "outputId": "7ec9f770-b642-4ac4-a9c8-8c6458b81153"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ruta al archivo en Google Drive\n",
        "ruta_archivo = '/content/drive/My Drive/dataset_normalized_lite5.csv'\n",
        "\n",
        "# Leer el archivo CSV y crear el DataFrame\n",
        "df = pd.read_csv(ruta_archivo)\n",
        "\n",
        "# Eliminar las columnas especificadas\n",
        "columns_to_drop = ['House_Hufflepuff', 'House_Ravenclaw', 'House_Slytherin']\n",
        "df = df.drop(columns=columns_to_drop)\n",
        "\n",
        "# Mostrar información sobre las columnas del DataFrame\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_Ku8O1sKbDS",
        "outputId": "ea5b38c7-b6ed-49ff-a15c-1f79898a83bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1277 entries, 0 to 1276\n",
            "Data columns (total 8 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   Best Hand                      1277 non-null   float64\n",
            " 1   Age                            1277 non-null   float64\n",
            " 2   House_Gryffindor               1277 non-null   float64\n",
            " 3   Herbology                      1277 non-null   float64\n",
            " 4   Defense Against the Dark Arts  1277 non-null   float64\n",
            " 5   Potions                        1277 non-null   float64\n",
            " 6   Charms                         1277 non-null   float64\n",
            " 7   Flying                         1277 non-null   float64\n",
            "dtypes: float64(8)\n",
            "memory usage: 79.9 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Vamos a poner como primera columna House_Gryffindor.\n",
        "- Vamos a mostrar las primeras filas del DataFrame."
      ],
      "metadata": {
        "id": "X3Hh3aNVMnWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Extraer la columna 'House_Gryffindor'\n",
        "house_gryffindor = df.pop('House_Gryffindor')\n",
        "\n",
        "# Insertar 'House_Gryffindor' como la primera columna\n",
        "df.insert(0, 'House_Gryffindor', house_gryffindor)\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame en forma de tabla\n",
        "print(tabulate(df.head(), headers='keys', tablefmt='fancy_grid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYxXepL3Muu_",
        "outputId": "642fc679-13a1-4882-ee77-aa06bae94913"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒════╤════════════════════╤═════════════╤════════════╤═════════════╤═════════════════════════════════╤═══════════╤═══════════╤════════════╕\n",
            "│    │   House_Gryffindor │   Best Hand │        Age │   Herbology │   Defense Against the Dark Arts │   Potions │    Charms │     Flying │\n",
            "╞════╪════════════════════╪═════════════╪════════════╪═════════════╪═════════════════════════════════╪═══════════╪═══════════╪════════════╡\n",
            "│  0 │                  0 │           0 │ -0.630834  │    0.866628 │                        1.0215   │ -0.702829 │  1.19791  │ -0.506096  │\n",
            "├────┼────────────────────┼─────────────┼────────────┼─────────────┼─────────────────────────────────┼───────────┼───────────┼────────────┤\n",
            "│  1 │                  0 │           1 │ -0.3078    │   -1.37602  │                        1.14449  │  0.412213 │ -1.01037  │ -1.39359   │\n",
            "├────┼────────────────────┼─────────────┼────────────┼─────────────┼─────────────────────────────────┼───────────┼───────────┼────────────┤\n",
            "│  2 │                  0 │           0 │ -0.346256  │    1.24909  │                        0.788043 │  0.889324 │  1.81875  │  0.0814973 │\n",
            "├────┼────────────────────┼─────────────┼────────────┼─────────────┼─────────────────────────────────┼───────────┼───────────┼────────────┤\n",
            "│  3 │                  1 │           0 │ -0.903875  │   -1.47361  │                       -1.25083  │ -1.65991  │ -1.54137  │  1.82674   │\n",
            "├────┼────────────────────┼─────────────┼────────────┼─────────────┼─────────────────────────────────┼───────────┼───────────┼────────────┤\n",
            "│  4 │                  0 │           1 │  0.0633057 │   -1.05091  │                        1.2626   │  1.86389  │ -0.527633 │ -0.586069  │\n",
            "╘════╧════════════════════╧═════════════╧════════════╧═════════════╧═════════════════════════════════╧═══════════╧═══════════╧════════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Separar variable objetivo (y) de características (X)\n",
        "y = df['House_Gryffindor']\n",
        "\n",
        "# 2. Seleccionar las características (excluyendo House_Gryffindor)\n",
        "X = df[['Best Hand', 'Age', 'Herbology', 'Defense Against the Dark Arts',\n",
        "        'Potions', 'Charms', 'Flying']]\n",
        "\n",
        "# 3. Agregar columna de 1's para el término de sesgo (bias)\n",
        "X = np.c_[np.ones(len(X)), X]\n",
        "\n",
        "# Convertir a arrays de numpy para operaciones más eficientes\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Las dimensiones deberían ser:\n",
        "# X: (1277, 8) - 1277 muestras, 8 características (incluyendo el bias)\n",
        "# y: (1277,) - 1277 etiquetas"
      ],
      "metadata": {
        "id": "NC3iJgN3Quun"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después de ejecutar el código anterior:\n",
        "- X será una matriz donde la primera columna es toda de 1's (para el bias) y las demás columnas son nuestras características\n",
        "- y será un vector con nuestras etiquetas (0 o 1 para Gryffindor)\n",
        "\n",
        "Los datos ya están normalizados, así que no necesitamos hacer ninguna normalización adicional"
      ],
      "metadata": {
        "id": "3uvDpS9NlVxb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para comprobar las dimensiones de las matrices puedes usar el atributo shape de NumPy."
      ],
      "metadata": {
        "id": "adteok9rll7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobar dimensiones\n",
        "print(\"Dimensiones de X:\", X.shape)\n",
        "print(\"Dimensiones de y:\", y.shape)\n",
        "\n",
        "# También podemos ver las primeras filas para verificar que la estructura es correcta\n",
        "print(\"\\nPrimeras 3 filas de X (mostrando el término de bias en la primera columna):\")\n",
        "headers = ['Bias', 'Best Hand', 'Age', 'Herbology', 'Defense Against the Dark Arts',\n",
        "           'Potions', 'Charms', 'Flying']\n",
        "\n",
        "# Crear una tabla con las primeras 3 filas de X\n",
        "table = tabulate(X[:3], headers=headers, floatfmt='.6f', tablefmt='fancy_grid')\n",
        "print(table)\n",
        "\n",
        "print(\"\\nPrimeros 3 valores de y:\")\n",
        "print(y[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0gdmCiwRDqi",
        "outputId": "fc82bdb8-ca5e-4b31-b240-b5cf740465fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones de X: (1277, 8)\n",
            "Dimensiones de y: (1277,)\n",
            "\n",
            "Primeras 3 filas de X (mostrando el término de bias en la primera columna):\n",
            "╒══════════╤═════════════╤═══════════╤═════════════╤═════════════════════════════════╤═══════════╤═══════════╤═══════════╕\n",
            "│     Bias │   Best Hand │       Age │   Herbology │   Defense Against the Dark Arts │   Potions │    Charms │    Flying │\n",
            "╞══════════╪═════════════╪═══════════╪═════════════╪═════════════════════════════════╪═══════════╪═══════════╪═══════════╡\n",
            "│ 1.000000 │    0.000000 │ -0.630834 │    0.866628 │                        1.021499 │ -0.702829 │  1.197913 │ -0.506096 │\n",
            "├──────────┼─────────────┼───────────┼─────────────┼─────────────────────────────────┼───────────┼───────────┼───────────┤\n",
            "│ 1.000000 │    1.000000 │ -0.307800 │   -1.376018 │                        1.144493 │  0.412213 │ -1.010371 │ -1.393587 │\n",
            "├──────────┼─────────────┼───────────┼─────────────┼─────────────────────────────────┼───────────┼───────────┼───────────┤\n",
            "│ 1.000000 │    0.000000 │ -0.346256 │    1.249093 │                        0.788043 │  0.889324 │  1.818754 │  0.081497 │\n",
            "╘══════════╧═════════════╧═══════════╧═════════════╧═════════════════════════════════╧═══════════╧═══════════╧═══════════╛\n",
            "\n",
            "Primeros 3 valores de y:\n",
            "[0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al correr el código anterior la salida debería ser algo como:\n",
        "- Para X: (1277, 8) - indicando 1277 filas y 8 columnas\n",
        "- Para y: (1277,) - indicando un vector de 1277 elementos\n",
        "\n",
        "En la visualización de las primeras filas de X, deberíamos ver que la primera columna es toda de 1's (el término de bias que agregamos)."
      ],
      "metadata": {
        "id": "2iQCgJ1Ulwe9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Función sigmoide\n",
        "Vamos a implementar la función sigmoide.  \n",
        "Esta función es crucial en la regresión logística ya que transforma cualquier número real en un valor entre 0 y 1, que podemos interpretar como una probabilidad.\n",
        "\n",
        "Esta es la función sigmoide\n",
        "\n",
        "σ(z) = 1/(1 + e^(-z))\n",
        "\n",
        "luego sustituiremos z por una función lineal con una serie de parámetros cuyos valores debemos estimar y que esos valores serán los pesos de nuestro modelo entrenado.\n",
        "\n",
        "Si la función z es:\n",
        "\n",
        "$$z = θ_0 + θ_1 \\cdot x_1 + θ_2 \\cdot x_2 + \\cdots + θ_n \\cdot x_n$$\n",
        "\n",
        "El valor de $n$ debe coincidir con el número de características de nuestro modelo, en este caso hay 7 características, por lo que $n=7$ puesto que se cumple que $θₙ = θ₇$\n",
        "\n",
        "Cuando preparamos los datos, añadimos una columna extra de 1's para el término de sesgo (bias). Así que ahora X tiene 8 columnas:\n",
        "- La primera columna de 1's (para θ₀, el término de sesgo)\n",
        "- Las 7 características originales\n",
        "\n",
        "Entonces la función z completa sería:\n",
        "\n",
        "z = θ₀ * 1 + θ₁ * x₁ + θ₂ * x₂ + θ₃ * x₃ + θ₄ * x₄ + θ₅ * x₅ + θ₆ * x₆ + θ₇ * x₇\n",
        "\n",
        "Donde:\n",
        "- θ₀ es el término de sesgo (bias) que multiplica a la columna de 1's que añadimos\n",
        "- θ₁ hasta θ₇ son los pesos que multiplican a nuestras 7 características originales\n",
        "\n",
        "Esto se puede escribir de forma más compacta como una multiplicación matricial:\n",
        "\n",
        "$$z = X \\cdot θ$$\n",
        "\n",
        "Donde:\n",
        "- $X$ es nuestra matriz de (1277, 8)\n",
        "- $θ$ será un vector de 8 parámetros que debemos estimar\n",
        "- $z$ será un vector de 1277 valores que luego pasaremos por la función sigmoide"
      ],
      "metadata": {
        "id": "Vv7DqHOARu6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "    Calcula la función sigmoide: σ(z) = 1/(1 + e^(-z))\n",
        "\n",
        "    Parámetros:\n",
        "    z: puede ser un número real, vector o matriz\n",
        "\n",
        "    Retorna:\n",
        "    Valor de la función sigmoide\n",
        "    \"\"\"\n",
        "    # Usamos np.clip para evitar desbordamiento numérico\n",
        "    # Limitamos los valores a [-250, 250] para evitar warnings de overflow\n",
        "    z_safe = np.clip(z, -250, 250)\n",
        "    return 1.0 / (1.0 + np.exp(-z_safe))\n",
        "\n",
        "# Podemos probar la función con algunos valores para verificar que funciona correctamente\n",
        "test_values = np.array([-10, -1, 0, 1, 10])\n",
        "print(\"Valores de prueba:\", test_values)\n",
        "print(\"Valores sigmoide:\", sigmoid(test_values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j28Xg9XIRwOu",
        "outputId": "a5edcd03-d4bf-4a75-f719-1f6a571945d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valores de prueba: [-10  -1   0   1  10]\n",
            "Valores sigmoide: [4.53978687e-05 2.68941421e-01 5.00000000e-01 7.31058579e-01\n",
            " 9.99954602e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El código anterior:\n",
        "- Utiliza NumPy para manejar operaciones vectorizadas\n",
        "- Incluye protección contra desbordamiento numérico usando np.clip\n",
        "- Puede manejar tanto valores individuales como arrays\n",
        "\n",
        "Al ejecutar este código, deberíamos ver que:\n",
        "- Para valores muy negativos, la función se acerca a 0\n",
        "- Para z = 0, la función da exactamente 0.5\n",
        "- Para valores muy positivos, la función se acerca a 1"
      ],
      "metadata": {
        "id": "0LDKA4TymMoi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Función de pérdida\n",
        "Vamos a implementar la función de pérdida logarítmica (log loss) para regresión logística.\n",
        "Para cada observación, la función de pérdida es:\n",
        "- Si y = 1: -log(h(x))\n",
        "- Si y = 0: -log(1 - h(x))\n",
        "\n",
        "Donde h(x) es nuestra predicción (la salida de la función sigmoide).\n",
        "\n",
        "Esto se puede escribir de forma compacta para todo el conjunto de datos como:\n",
        "$$J(θ) = -(1/m) * Σ [y * log(h(x)) + (1-y) * log(1-h(x))]$$\n",
        "Donde:\n",
        "- m es el número de observaciones (1277 en nuestro caso)\n",
        "- y son los valores reales\n",
        "- h(x) son las predicciones (después de aplicar la sigmoide)\n",
        "- Σ representa la suma sobre todas las observaciones"
      ],
      "metadata": {
        "id": "TC8o7w9ZWSXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(X, y, theta):\n",
        "    \"\"\"\n",
        "    Calcula la función de pérdida logarítmica\n",
        "\n",
        "    Parámetros:\n",
        "    X: matriz de características (incluyendo columna de 1's)\n",
        "    y: vector de etiquetas reales\n",
        "    theta: vector de parámetros\n",
        "\n",
        "    Retorna:\n",
        "    J: valor de la función de pérdida\n",
        "    \"\"\"\n",
        "    m = len(y)\n",
        "\n",
        "    # Calcular predicciones\n",
        "    z = np.dot(X, theta)\n",
        "    h = sigmoid(z)\n",
        "\n",
        "    # Calcular pérdida logarítmica\n",
        "    # Añadimos un pequeño valor epsilon para evitar log(0)\n",
        "    epsilon = 1e-15\n",
        "    J = -(1/m) * np.sum(y * np.log(h + epsilon) + (1-y) * np.log(1 - h + epsilon))\n",
        "\n",
        "    return J"
      ],
      "metadata": {
        "id": "wUgKhGVuWS7c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El código anterior:\n",
        "- Calcula z = X·θ\n",
        "- Aplica la función sigmoide para obtener h(x)\n",
        "- Calcula la pérdida logarítmica\n",
        "- Incluye un pequeño valor epsilon para evitar problemas numéricos con log(0)"
      ],
      "metadata": {
        "id": "-oLhXQQJWSUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cálculo del Gradiente\n",
        "Para el cálculo del gradiente, necesitamos derivar la función de pérdida con respecto a cada parámetro θⱼ.\n",
        "\n",
        "En regresión logística, el gradiente tiene una forma muy elegante:\n",
        "∂J/∂θ = (1/m) * X^T * (h(x) - y)\n",
        "\n",
        "Donde:\n",
        "- m es el número de observaciones (1277)\n",
        "- X^T es la matriz X transpuesta\n",
        "- h(x) - y es la diferencia entre nuestras predicciones y los valores reales\n",
        "\n"
      ],
      "metadata": {
        "id": "WZ9WEKvRTXoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient(X, y, theta):\n",
        "    \"\"\"\n",
        "    Calcula el gradiente de la función de pérdida\n",
        "\n",
        "    Parámetros:\n",
        "    X: matriz de características (incluyendo columna de 1's)\n",
        "    y: vector de etiquetas reales\n",
        "    theta: vector de parámetros actual\n",
        "\n",
        "    Retorna:\n",
        "    gradient: vector con las derivadas parciales respecto a cada parámetro\n",
        "    \"\"\"\n",
        "    m = len(y)\n",
        "\n",
        "    # Calcular predicciones\n",
        "    z = np.dot(X, theta)\n",
        "    h = sigmoid(z)\n",
        "\n",
        "    # Calcular gradiente\n",
        "    gradient = (1/m) * np.dot(X.T, (h - y))\n",
        "\n",
        "    return gradient"
      ],
      "metadata": {
        "id": "hiS7lwYPTwQ8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El código anterior:\n",
        "- Calcula las predicciones actuales usando los parámetros theta\n",
        "- Calcula el error (h - y)\n",
        "- Multiplica por X transpuesta y normaliza por m\n",
        "\n",
        "El gradiente resultante tendrá 8 componentes (una por cada parámetro θ), que nos indicarán en qué dirección debemos actualizar cada parámetro para minimizar la función de pérdida."
      ],
      "metadata": {
        "id": "8moKBLs0T8kw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descenso del Gradiente\n",
        "Implementaremos el algoritmo de descenso del gradiente que usará todas las funciones que hemos creado anteriormente.\n",
        "\n",
        "Early stopping: detener el algoritmo cuando el cambio en el coste sea menor que un umbral (por ejemplo, 1e-8)\n",
        "\n",
        "Para implementear el Early stopping:\n",
        "- Agregamos el parámetro epsilon para el umbral\n",
        "- Comparamos el coste actual con el anterior\n",
        "- Si la diferencia es menor que epsilon, detenemos el algoritmo\n",
        "- Informamos en qué iteración se alcanzó la convergencia\n",
        "\n",
        "Esto debería reducir significativamente el tiempo de ejecución al evitar iteraciones innecesarias una vez que el modelo haya convergido."
      ],
      "metadata": {
        "id": "Se6Bw8wAUL-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, learning_rate=0.1, num_iterations=1000, epsilon=1e-8):\n",
        "    \"\"\"\n",
        "    Implementa el descenso del gradiente con early stopping\n",
        "\n",
        "    Parámetros:\n",
        "    X: matriz de características (incluyendo columna de 1's)\n",
        "    y: vector de etiquetas reales\n",
        "    learning_rate: tasa de aprendizaje (alpha)\n",
        "    num_iterations: número máximo de iteraciones\n",
        "    epsilon: umbral para early stopping\n",
        "\n",
        "    Retorna:\n",
        "    theta: parámetros optimizados\n",
        "    cost_history: lista con el valor de la función de pérdida en cada iteración\n",
        "    \"\"\"\n",
        "    # Inicializar parámetros theta con ceros\n",
        "    theta = np.zeros(X.shape[1])\n",
        "\n",
        "    # Lista para guardar el historial de costes\n",
        "    cost_history = []\n",
        "\n",
        "    # Calcular coste inicial\n",
        "    prev_cost = compute_cost(X, y, theta)\n",
        "    cost_history.append(prev_cost)\n",
        "\n",
        "    # Descenso del gradiente\n",
        "    for i in range(num_iterations):\n",
        "        # Calcular gradiente y actualizar parámetros\n",
        "        gradient = compute_gradient(X, y, theta)\n",
        "        theta = theta - learning_rate * gradient\n",
        "\n",
        "        # Calcular nuevo coste\n",
        "        current_cost = compute_cost(X, y, theta)\n",
        "        cost_history.append(current_cost)\n",
        "\n",
        "        # Imprimir progreso cada 100 iteraciones\n",
        "        if i % 1000 == 0:\n",
        "            print(f'Iteración {i}: Coste = {current_cost}')\n",
        "\n",
        "        # Early stopping\n",
        "        if abs(prev_cost - current_cost) < epsilon:\n",
        "            print(f'\\nConvergencia alcanzada en la iteración {i}')\n",
        "            print(f'Diferencia en coste: {abs(prev_cost - current_cost)}')\n",
        "            break\n",
        "\n",
        "        prev_cost = current_cost\n",
        "\n",
        "    return theta, cost_history"
      ],
      "metadata": {
        "id": "c0S-AkhXUSU8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este algoritmo:\n",
        "1. Inicializa los parámetros θ con ceros\n",
        "2. En cada iteración:\n",
        "    - Calcula el gradiente actual\n",
        "    - Actualiza los parámetros usando la fórmula: θ = θ - α * gradiente\n",
        "    - Guarda el valor de la función de pérdida\n",
        "3. Retorna los parámetros optimizados y el historial de costes\n",
        "\n",
        "Podemos ejecutarlo así:"
      ],
      "metadata": {
        "id": "mywGNH3yUkZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparámetros\n",
        "learning_rate = 0.1\n",
        "num_iterations = 100_000\n",
        "# Ejecutar el descenso del gradiente\n",
        "theta_optimal, cost_history = gradient_descent(X, y, learning_rate, num_iterations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtYs6LpGUl-p",
        "outputId": "031fa1ec-6430-4e1b-ac48-112f3f1e3135"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteración 0: Coste = 0.6537569229648154\n",
            "Iteración 1000: Coste = 0.051618788591932106\n",
            "Iteración 2000: Coste = 0.04746862053989086\n",
            "Iteración 3000: Coste = 0.04576635291997387\n",
            "Iteración 4000: Coste = 0.044801627076967165\n",
            "Iteración 5000: Coste = 0.04417646848250042\n",
            "Iteración 6000: Coste = 0.04373418874275613\n",
            "Iteración 7000: Coste = 0.04340134660257361\n",
            "Iteración 8000: Coste = 0.043139329631335877\n",
            "Iteración 9000: Coste = 0.04292596845806905\n",
            "Iteración 10000: Coste = 0.04274764423387861\n",
            "Iteración 11000: Coste = 0.04259553490739291\n",
            "Iteración 12000: Coste = 0.04246367470089986\n",
            "Iteración 13000: Coste = 0.04234788192144806\n",
            "Iteración 14000: Coste = 0.042245133928530465\n",
            "Iteración 15000: Coste = 0.0421531863852637\n",
            "Iteración 16000: Coste = 0.04207033263037326\n",
            "Iteración 17000: Coste = 0.04199524677885572\n",
            "Iteración 18000: Coste = 0.041926878627245714\n",
            "Iteración 19000: Coste = 0.041864381587421215\n",
            "Iteración 20000: Coste = 0.04180706223448379\n",
            "Iteración 21000: Coste = 0.041754344325962804\n",
            "Iteración 22000: Coste = 0.0417057427074212\n",
            "Iteración 23000: Coste = 0.04166084409435287\n",
            "Iteración 24000: Coste = 0.04161929271421329\n",
            "Iteración 25000: Coste = 0.04158077943384568\n",
            "Iteración 26000: Coste = 0.04154503341982849\n",
            "Iteración 27000: Coste = 0.041511815662276276\n",
            "Iteración 28000: Coste = 0.04148091388539023\n",
            "Iteración 29000: Coste = 0.041452138501276006\n",
            "Iteración 30000: Coste = 0.041425319356836195\n",
            "Iteración 31000: Coste = 0.04140030308965645\n",
            "Iteración 32000: Coste = 0.041376950956166274\n",
            "Iteración 33000: Coste = 0.041355137029623595\n",
            "Iteración 34000: Coste = 0.04133474669049324\n",
            "Iteración 35000: Coste = 0.04131567535021353\n",
            "Iteración 36000: Coste = 0.04129782736301916\n",
            "Iteración 37000: Coste = 0.04128111509071295\n",
            "Iteración 38000: Coste = 0.041265458092978276\n",
            "Iteración 39000: Coste = 0.0412507824216618\n",
            "Iteración 40000: Coste = 0.041237020001912546\n",
            "Iteración 41000: Coste = 0.041224108086487826\n",
            "Iteración 42000: Coste = 0.04121198877218451\n",
            "Iteración 43000: Coste = 0.041200608569417284\n",
            "Iteración 44000: Coste = 0.0411899180175828\n",
            "\n",
            "Convergencia alcanzada en la iteración 44573\n",
            "Diferencia en coste: 9.999928100856703e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy\n",
        "Aquí si usaremos la librería `sklearn` para calcular la precisión del model.\n",
        "\n",
        "Vamos a calcular la accuracy del modelo. Para esto, necesitamos:\n",
        "- Hacer predicciones usando nuestros parámetros theta optimizados\n",
        "- Convertir las probabilidades en clases (0 o 1)\n",
        "- Comparar con los valores reales usando sklearn.metrics"
      ],
      "metadata": {
        "id": "aq6irznAdbbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def predict(X, theta):\n",
        "    \"\"\"\n",
        "    Realiza predicciones usando los parámetros optimizados\n",
        "\n",
        "    Parámetros:\n",
        "    X: matriz de características\n",
        "    theta: parámetros optimizados\n",
        "\n",
        "    Retorna:\n",
        "    y_pred: predicciones (0 o 1)\n",
        "    \"\"\"\n",
        "    # Calcular probabilidades\n",
        "    z = np.dot(X, theta)\n",
        "    probabilities = sigmoid(z)\n",
        "\n",
        "    # Convertir a clases (0 o 1)\n",
        "    predictions = (probabilities >= 0.5).astype(int)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Hacer predicciones\n",
        "y_pred = predict(X, theta_optimal)\n",
        "\n",
        "# Calcular accuracy\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "print(f'Accuracy del modelo: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAUi4LYIdfKN",
        "outputId": "c613ca34-c0ff-4537-9be9-9546cf8d4f38"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy del modelo: 0.9922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El código anterior:\n",
        "- Define una función predict que:\n",
        "    - Calcula z = X·θ\n",
        "    - Aplica la función sigmoide\n",
        "    - Convierte probabilidades a clases usando 0.5 como umbral\n",
        "\n",
        "- Usa los parámetros theta_optimal que obtuvimos del descenso del gradiente\n",
        "- Calcula la accuracy usando sklearn.metrics"
      ],
      "metadata": {
        "id": "A2MEvFfKsD6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ¿Qué es la Accuracy?\n",
        "La Accuracy (precisión o exactitud) es una de las métricas más intuitivas para evaluar modelos de clasificación. Se basa en un concepto simple pero poderoso:\n",
        "\n",
        "Accuracy = (Número de predicciones correctas) / (Número total de predicciones)\n",
        "\n",
        "En el contexto de clasificación binaria (como nuestro caso con Gryffindor/No Gryffindor), podemos desglosarlo así:\n",
        "\n",
        "- Verdaderos Positivos (TP): Predijimos Gryffindor y era Gryffindor\n",
        "- Verdaderos Negativos (TN): Predijimos No-Gryffindor y era No-Gryffindor\n",
        "- Falsos Positivos (FP): Predijimos Gryffindor pero era No-Gryffindor\n",
        "- Falsos Negativos (FN): Predijimos No-Gryffindor pero era Gryffindor\n",
        "\n",
        "La fórmula completa sería:\n",
        "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "\n",
        "Es importante notar que:\n",
        "- La Accuracy es útil cuando las clases están balanceadas\n",
        "- No es tan informativa cuando hay desbalance de clases\n",
        "- Un valor de 0.5 en clasificación binaria equivale a predicción aleatoria\n",
        "- Un valor de 1.0 significa predicción perfecta\n",
        "\n",
        "Dos ejemplos:\n",
        "- si nuestro modelo predice correctamente la casa de 1000 estudiantes de un total de 1277, la accuracy sería 1000/1277 ≈ 0.783 o 78.3%.\n",
        "- si nuestro modelo predice correctamente la casa de 1267 estudiantes de un total de 1277, la accuracy sería 1267/1277 ≈ 0.992169146436962 o **99,22%**. En este caso solo se han clasificado incorrectamente 10 casos de un total de 1277."
      ],
      "metadata": {
        "id": "U4xqNSSUtE1r"
      }
    }
  ]
}