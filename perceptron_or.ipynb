{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVfxGeV3DQtry28x5wds33",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/financieras/ai/blob/main/perceptron_or.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptrón OR\n",
        "Usando un perceptrón simple realizaremos la modelización de una puerta lógica OR."
      ],
      "metadata": {
        "id": "jR7adUpkUWhG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pesos y bias aleatorios\n",
        "Al ejecutar el siguiente código las Salidas obtenidas pueden variar al cambiar aleatoriamene los pesos y el bias (sesgo) que se utilizan.\n",
        "\n",
        "Para simular una puerta lógica OR la salida esperada $y$ debería venir dada por esta **tabla de verdad**:\n",
        "\n",
        "| $x_1$ | $x_2$ | $y$ |\n",
        "|----|----|----|\n",
        "| 0  |  0 |  0 |\n",
        "| 0  |  1 |  1 |\n",
        "| 1  |  0 |  1 |\n",
        "| 1  |  1 |  1 |\n"
      ],
      "metadata": {
        "id": "MllPjcO0UnbI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWaFBP3dJwxD",
        "outputId": "efaa7570-d013-4157-c6cf-d06165c6d518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrada: [0 0], Salida esperada: 0, Salida obtenida: 0\n",
            "Entrada: [0 1], Salida esperada: 1, Salida obtenida: 1\n",
            "Entrada: [1 0], Salida esperada: 1, Salida obtenida: 0\n",
            "Entrada: [1 1], Salida esperada: 1, Salida obtenida: 1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos la función de activación escalón\n",
        "def step_function(x):\n",
        "  return 1 if x >= 0 else 0\n",
        "\n",
        "# Inicializamos los pesos y el bias aleatoriamente\n",
        "def initialize_parameters():\n",
        "  weights = np.random.uniform(-1, 1, size=2)  # Dos pesos para las dos entradas\n",
        "  bias = np.random.uniform(-1, 1, size=1)     # Pesos entre -1 y 1\n",
        "  return weights, bias\n",
        "\n",
        "# Calculamos la salida del perceptrón\n",
        "def perceptron(x, weights, bias):\n",
        "  # Suma ponderada\n",
        "  z = np.dot(x, weights) + bias\n",
        "  # Aplicamos la función de activación\n",
        "  y = step_function(z)\n",
        "  return y\n",
        "\n",
        "# Datos de entrenamiento (tabla de verdad de la puerta OR)\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 1, 1, 1])\n",
        "\n",
        "# Inicializamos los parámetros\n",
        "weights, bias = initialize_parameters()\n",
        "\n",
        "# Entrenamiento (en este caso, simplemente verificamos la salida)\n",
        "for i in range(len(X)):\n",
        "  x = X[i]\n",
        "  y_pred = perceptron(x, weights, bias)\n",
        "  print(f\"Entrada: {x}, Salida esperada: {y[i]}, Salida obtenida: {y_pred}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prueba y error\n",
        "Hemos introducido un bucle `while` para buscar el caso en el que los pesos y el bias nos proporcionan el resultado esperado de una puerta lógica OR.\n",
        "\n",
        "Lo que hace el bucle `while` es ir probando valores aleatorios hasta encontrar unos pesos y bias que logran obtener la tabla de verdad que estamos buscando. Aunque no son los únicos valores de pesos y bias que lo logran, hay muchos otros valores de pesos y bias que se pueden llegar a obtener aleatoriamente y que logran esta misma tabla de verdad.\n",
        "\n",
        "Lo que nos gustaría en próximos códigos es lograr un mecanismo de aprendizaje automático que logre estos pesos y bias exitosos de una forma dirigida y no simplemente probando por azar."
      ],
      "metadata": {
        "id": "Qd5kaLReWbZu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e89af934-62af-4fd0-b0e6-1c90baaf4a26",
        "id": "__zhjOgJPicp"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights: [0.64 0.76] bias: [-0.13]\n",
            "Entrada: [0 0], Salida esperada: 0, Salida obtenida: 0\n",
            "Entrada: [0 1], Salida esperada: 1, Salida obtenida: 1\n",
            "Entrada: [1 0], Salida esperada: 1, Salida obtenida: 1\n",
            "Entrada: [1 1], Salida esperada: 1, Salida obtenida: 1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos la función de activación escalón\n",
        "def step_function(x):\n",
        "  return 1 if x >= 0 else 0\n",
        "\n",
        "# Inicializamos los pesos y el bias aleatoriamente\n",
        "def initialize_parameters():\n",
        "  weights = np.random.uniform(-1, 1, size=2)  # Dos pesos para las dos entradas\n",
        "  bias = np.random.uniform(-1, 1, size=1)     # Pesos entre -1 y 1\n",
        "  return weights, bias\n",
        "\n",
        "# Calculamos la salida del perceptrón\n",
        "def perceptron(x, weights, bias):\n",
        "  # Suma ponderada\n",
        "  z = np.dot(x, weights) + bias\n",
        "  # Aplicamos la función de activación\n",
        "  y = step_function(z)\n",
        "  return y\n",
        "\n",
        "# Datos de entrenamiento (tabla de verdad de la puerta OR)\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 1, 1, 1])\n",
        "\n",
        "while True:\n",
        "    # Inicializamos los parámetros\n",
        "    weights, bias = initialize_parameters()\n",
        "    if  perceptron([0,0], weights, bias) == 0 and \\\n",
        "        perceptron([0,1], weights, bias) == 1 and \\\n",
        "        perceptron([1,0], weights, bias) == 1 and \\\n",
        "        perceptron([1,1], weights, bias) == 1:\n",
        "        print(\"weights:\", np.around(weights, 2), \"bias:\", np.round(bias, 2))\n",
        "        break\n",
        "\n",
        "# Entrenamiento (en este caso, simplemente verificamos la salida)\n",
        "for i in range(len(X)):\n",
        "  x = X[i]\n",
        "  y_pred = perceptron(x, weights, bias)\n",
        "  print(f\"Entrada: {x}, Salida esperada: {y[i]}, Salida obtenida: {y_pred}\")\n",
        "\n",
        "#print(f\"Entrada: {[0, 0]}, Salida esperada {0}, Salida obtenida: {perceptron([0,0], weights, bias)}\")"
      ]
    }
  ]
}