{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/financieras/ai/blob/main/multicapa/subject_es/Proyecto_Perceptron_Multicapa_es.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gehvxnt0hNzv"
   },
   "source": [
    "# Proyecto de Aprendizaje Automático\n",
    "## Perceptrón Multicapa\n",
    "Este proyecto es una introducción a las redes neuronales artificiales: con la implementación de perceptrones multicapa.\n",
    "\n",
    "Versión: 5.0\n",
    "\n",
    "## Contenidos\n",
    "1. Introducción\n",
    "    - Un poco de historia\n",
    "    - Perceptrón multicapa\n",
    "    - Perceptrón\n",
    "2. Objetivos\n",
    "3. Instrucciones generales\n",
    "4. Parte obligatoria\n",
    "    - Preámbulo\n",
    "    - Conjunto de datos (dataset)\n",
    "    - Implementación\n",
    "    - Entrega\n",
    "5. Parte bonus\n",
    "6. Entrega y evaluación por pares\n",
    "\n",
    "## Capítulo I\n",
    "### Introducción\n",
    "En el lenguaje de tu elección vas a implementar un perceptrón multicapa para predecir si un cáncer es maligno o benigno en un conjunto de datos de diagnóstico de cáncer de mama en Wisconsin.\n",
    "\n",
    "### 1.1 Un poco de historia\n",
    "El aprendizaje automático es un campo vasto del cual las redes neuronales artificiales son solo un pequeño subconjunto. Sin embargo, vamos a abordarlo ya que es una herramienta muy poderosa que resurgió hace unos años.\n",
    "\n",
    "Contrariamente a lo que uno podría pensar, las redes neuronales artificiales han existido durante mucho tiempo. En su artículo de 1948 \"[Intelligent Machinery](https://www.alanturing.net/intelligent_machinery)\", Alan Turing introdujo un tipo de redes neuronales llamadas \"B-Type Unorganised Machine\" que él consideraba como el modelo más simple posible del sistema nervioso.\n",
    "\n",
    "El perceptrón fue inventado por Frank Rosenblatt en 1957; es un clasificador lineal de una sola capa, y también una de las primeras redes neuronales en ser implementadas. Desafortunadamente los resultados no fueron tan buenos como se esperaba y la idea fue abandonada. Un poco más de 10 años después, el algoritmo fue mejorado como el *perceptrón multicapa* y se utilizó nuevamente.\n",
    "\n",
    "### 1.2 Perceptrón Multicapa\n",
    "El perceptrón multicapa es una red feedforward (lo que significa que los datos fluyen desde la capa de entrada hacia la capa de salida) definida por la presencia de una o más capas ocultas así como una interconexión de todas las neuronas de una capa a la siguiente.\n",
    "\n",
    "<img src=\"https://github.com/financieras/ai/blob/main/multicapa/subject_es/multicapa.png?raw=1\" alt=\"cuadrados con puntos\" width=\"800\"/>\n",
    "\n",
    "El diagrama representa una red que contiene 4 capas densas (también llamadas capas totalmente conectadas). Sus entradas consisten en 4 neuronas y su salida de 2 (perfecto para clasificación binaria). Los pesos de una capa a la siguiente están representados por matrices bidimensionales notadas como $W_{l_{j}l_{j+1}}$. La matriz $W_{l_{0}l_{1}}$ es de tamaño (3, 4) por ejemplo, ya que contiene los pesos de las conexiones entre la capa $l_0$ y la capa $l_1$.\n",
    "\n",
    "El sesgo (bias) a menudo se representa como una neurona especial que no tiene entradas y con una salida siempre igual a 1. Como un perceptrón, está conectado a todas las neuronas de la siguiente capa (las neuronas de sesgo están notadas como $b^{l_j}$ en el diagrama). El sesgo generalmente es útil ya que permite \"controlar el comportamiento\" de una capa.\n",
    "\n",
    "### 1.3 Perceptrón\n",
    "El perceptrón es el tipo de neurona del que está compuesto el *perceptrón multicapa*. Se define por la presencia de una o más conexiones de entrada, una función de activación y una única salida. Cada conexión contiene un peso (también llamado parámetro) que se aprende durante la fase de entrenamiento.\n",
    "\n",
    "<img src=\"https://github.com/financieras/ai/blob/main/multicapa/subject_es/perceptron.png?raw=1\" alt=\"cuadrados con puntos\" width=\"480\"/>\n",
    "\n",
    "Son necesarios dos pasos para obtener la salida de una neurona. El primero consiste en calcular la suma ponderada de las salidas de la capa anterior con los pesos de las conexiones de entrada de la neurona, lo que da:\n",
    "\n",
    "$$\\textit{Suma ponderada} = \\sum_{k=0}^{N-1}(w_k \\cdot x_k) + bias$$\n",
    "\n",
    "\n",
    "\n",
    "El segundo paso consiste en aplicar una función de activación a esta suma ponderada, siendo la salida de esta función la salida del perceptrón, y puede entenderse como el umbral por encima del cual la neurona se activa (las funciones de activación pueden tomar muchas formas, eres libre de elegir la que quieras dependiendo del modelo a entrenar, aquí hay algunas de las más frecuentemente utilizadas para darte una idea: sigmoide, tangente hiperbólica, unidad lineal rectificada).\n",
    "\n",
    "## Capítulo II\n",
    "### Objetivos\n",
    "El objetivo de este proyecto es darte una primera aproximación a las redes neuronales artificiales y hacer que implementes los algoritmos en el corazón del proceso de entrenamiento. Al mismo tiempo, vas a tener que familiarizarte nuevamente con la manipulación de derivadas y álgebra lineal ya que son herramientas matemáticas indispensables para el éxito del proyecto.\n",
    "\n",
    "## Capítulo III\n",
    "### Instrucciones Generales\n",
    "- Este proyecto solo será evaluado por humanos. Eres libre de organizar y nombrar tus archivos como desees mientras respetes las restricciones listadas a continuación.\n",
    "- Eres libre de usar cualquier lenguaje que quieras, no tienes restricciones en ese punto.\n",
    "- No se permiten bibliotecas que manejen la implementación de redes neuronales artificiales o los algoritmos subyacentes, debes codificar todo desde cero, sin embargo, puedes usar bibliotecas para manejar álgebra lineal y para mostrar las curvas de aprendizaje.\n",
    "- En el caso de un lenguaje compilado, debes enviar un Makefile. Este Makefile debe compilar el proyecto y debe contener las reglas de compilación usuales. Debe recompilar y reenlazar el programa solo cuando sea necesario. Las dependencias también deben descargarse/instalarse con el Makefile según sea necesario.\n",
    "- La norma no se aplica en este proyecto. Sin embargo, se te pedirá que seas claro y estructurado en la concepción de tu código fuente.\n",
    "\n",
    "## Capítulo IV\n",
    "### Parte Obligatoria\n",
    "\n",
    "#### 4.1 Preámbulo\n",
    "Una parte no negligible de la evaluación se basará en tu comprensión de la fase de entrenamiento (también llamada fase de aprendizaje) y los algoritmos subyacentes. Se te pedirá que expliques a tu corrector las nociones de **feedforward**, **backpropagation** y **gradient descent**. Los puntos se atribuirán dependiendo de la claridad de tus explicaciones. Estas nociones son importantes para los siguientes proyectos de la rama y representarán un verdadero activo si deseas continuar en este campo.\n",
    "\n",
    "#### 4.2 Conjunto de datos (dataset)\n",
    "El conjunto de datos se proporciona en los recursos. Es un archivo `csv` de 32 columnas, siendo la columna diagnosis la etiqueta que quieres aprender dados todos los otros atributos de un ejemplo, puede ser el valor `M` o `B` (por maligno o benigno).\n",
    "\n",
    "Los atributos del conjunto de datos describen las características de un núcleo celular de masa mamaria extraída con [aspiración por aguja fina](https://en.wikipedia.org/wiki/Fine-needle_aspiration). (Para información más detallada, ve [aquí](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names)).\n",
    "\n",
    "Como verás, hay un importante trabajo de comprensión de datos antes de comenzar a implementar el algoritmo que será capaz de clasificarlo. Una buena práctica sería comenzar jugando con el conjunto de datos mostrándolo con gráficos, visualizando y manipulando sus diferentes características.\n",
    "\n",
    "Tienes que separar tu conjunto de datos en dos partes por ti mismo, una para entrenamiento y otra para validación.\n",
    "\n",
    "> Los datos están en bruto y deben ser preprocesados antes de ser utilizados para la fase de entrenamiento.\n",
    "\n",
    "#### 4.3 Implementación\n",
    "Tu implementación de red neuronal debe contener al menos dos capas ocultas por defecto.\n",
    "\n",
    "La idea es hacer que escribas un programa un poco más modular (puedes usar un archivo o directamente como argumentos).\n",
    "\n",
    "Por ejemplo, agregando una capa oculta en archivo:\n",
    "\n",
    "```python\n",
    "network = model.createNetwork([\n",
    "    layers.denseLayer(input_shape, activation=\"sigmoid\"),\n",
    "    layers.denseLayer(25, activation=\"sigmoid\", weights_initializer=\"he_Uniform\"),\n",
    "    layers.denseLayer(25, activation=\"sigmoid\", weights_initializer=\"he_uniform\"),\n",
    "    layers.denseLayer(25, activation=\"sigmoid\", weights_initializer=\"he_uniform\"),\n",
    "    layers.denseLayer(output_shape, activation=\"softmax\", weights_initializer=\"he_uniform\")\n",
    "])\n",
    "model.fit(network, dt_train, dt_valid, loss=\"binary_crossentropy\", learning_rate=0.0165, batch_size=8, epochs=85)\n",
    "```\n",
    "\n",
    "O por ejemplo con argumentos:\n",
    "```bash\n",
    "python train.py --layer 25 25 25 --epochs 85 --loss binary_crossentropy --batch_size 8 --learning_rate 0.0165\n",
    "```\n",
    "\n",
    "También debes implementar la función softmax en la capa de salida para obtener la salida como una distribución probabilística.\n",
    "\n",
    "Para evaluar el rendimiento de tu modelo de manera robusta durante el entrenamiento, dividirás tu conjunto de datos en dos partes: una para el entrenamiento y otra para la validación (el conjunto de datos de validación se usa para determinar la precisión de tu modelo en ejemplos desconocidos).\n",
    "\n",
    "También implementarás dos gráficos de curvas de aprendizaje que se mostrarán al final de la fase de entrenamiento (eres libre de usar cualquier biblioteca que quieras para este propósito).\n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td width=\"50%\">\n",
    "      <figure>\n",
    "        <img src=\"https://github.com/financieras/ai/blob/main/multicapa/subject_es/loss.png?raw=1\" alt=\"cuadrados con puntos\" width=\"100%\"/>\n",
    "        <figcaption>Figura 4.1: Pérdida</figcaption>\n",
    "      </figure>\n",
    "    </td>\n",
    "    <td width=\"50%\">\n",
    "      <figure>\n",
    "        <img src=\"https://github.com/financieras/ai/blob/main/multicapa/subject_es/accuracy.png?raw=1\" alt=\"cuadrados con puntos\" width=\"100%\"/>\n",
    "        <figcaption>Figura 4.2: Precisión</figcaption>\n",
    "      </figure>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "#### 4.4 Entrega\n",
    "Entregarás tres programas:\n",
    "- Un programa para separar el conjunto de datos en dos partes, una para entrenamiento y otra para validación\n",
    "- Un programa de entrenamiento\n",
    "- Un programa de predicción\n",
    "(O puedes entregar un solo programa con una opción para cambiar entre las tres fases)\n",
    "\n",
    "Para visualizar el rendimiento de tu modelo durante el entrenamiento, mostrarás en cada época las métricas de entrenamiento y validación.\n",
    "\n",
    "Por ejemplo:\n",
    "```\n",
    "python mlp.py --dataset dt_training.csv\n",
    "x_train shape : (352, 30)\n",
    "x_valid shape : (87, 30)\n",
    "epoch 01/80 - loss: 0.6882 - val_loss: 0.6988\n",
    "...\n",
    "epoch 39/80 - loss: 0.0870 - val_loss: 0.0506\n",
    "epoch 50/80 - loss: 0.0859 - val_loss: 0.0505\n",
    "epoch 51/80 - loss: 0.0858 - val_loss: 0.0500\n",
    "...\n",
    "epoch 80/80 - loss: 0.0650 - val_loss: 0.0585\n",
    "# saving model \"./saved_model.npy\" to disk...\n",
    "```\n",
    "\n",
    "- Para el programa de separación se te permite usar una semilla para obtener un resultado repetible, porque muchos factores aleatorios entran en juego (la inicialización de pesos y sesgos por ejemplo)\n",
    "- El programa de entrenamiento usará backpropagation y gradient descent para aprender en el conjunto de datos de entrenamiento y guardará el modelo (topología de la red y pesos) al final de su ejecución.\n",
    "- El programa de predicción cargará los pesos aprendidos en la fase anterior, realizará una predicción en un conjunto dado (que también será cargado), luego lo evaluará usando la función de error de entropía cruzada binaria:\n",
    "\n",
    "$$L = -\\sum[y_m \\log p_m + (1 - y_m) \\log(1 - p_m)]$$\n",
    "\n",
    "## Capítulo V\n",
    "### Parte Bonus\n",
    "La parte bonus solo será evaluada si la parte obligatoria fue perfectamente realizada.\n",
    "\n",
    "Eres libre de implementar cualquier funcionalidad que creas que podría ser interesante. Sin embargo, aquí hay una lista no exhaustiva de bonificaciones:\n",
    "- Una función de optimización más compleja (por ejemplo: Nesterov momentum, RMSprop, Adam, ...).\n",
    "- Visualización de múltiples curvas de aprendizaje en el mismo gráfico (realmente útil para comparar diferentes modelos).\n",
    "- Un histórico de las métricas obtenidas durante el entrenamiento.\n",
    "- La implementación de early stopping.\n",
    "- Evaluar la fase de aprendizaje con múltiples métricas.\n",
    "\n",
    "La parte bonus solo será evaluada si la parte obligatoria es perfecta. Perfecto significa que la parte obligatoria ha sido integralmente realizada y funciona sin fallos. Si no has pasado todos los requisitos obligatorios, tu parte bonus no será evaluada en absoluto.\n",
    "\n",
    "## Capítulo VI\n",
    "### Entrega y Evaluación por Pares\n",
    "Entrega tu trabajo en tu repositorio Git como de costumbre. Solo el trabajo dentro de tu repositorio será evaluado durante la defensa. No dudes en verificar dos veces los nombres de tus carpetas y archivos para asegurarte de que sean correctos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AB_UnNEvlQAL"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM1zo/y/GkbNhF8WNfIJ8T0",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
